"""
üìä NASDAQ Model Leaderboard & Interactive Backtester
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

This section of the Streamlit app provides:
- A leaderboard of trained models with performance metrics
- Interactive visualizations to compare models
- A backtesting tool to simulate predictions on specific stocks and dates

üîß Key Features:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Filters for F1 score, average error, and hit rate
- Bubble charts for visual model comparison
- Error standard deviation analysis
- Manual backtest on selected stock/date/model

üìÅ Inputs:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- `model_performance_summary.csv` ‚Äî generated by evaluation pipeline
- Trained models (.pkl)
- Feature datasets (.parquet)

üì§ Outputs:
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
- Streamlit-rendered charts and tables
- Optional backtest results for selected scenario
"""

import os
import glob
import joblib
import pandas as pd
import numpy as np
from sklearn.metrics import f1_score, precision_score, recall_score
from tqdm import tqdm
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go  # make sure this is at the top
from plotly.subplots import make_subplots

# --- Session state defaults ---
if "min_f1" not in st.session_state:
    st.session_state.min_f1 = 0.2
if "max_err" not in st.session_state:
    st.session_state.max_err = 10.0
if "min_hit" not in st.session_state:
    st.session_state.min_hit = 0.3

# In sidebar or top of app
DEBUG_MODE = st.sidebar.checkbox("üêû Enable Debug Logging", value=False)

# === CONFIG ===
TRAIN_DIR = r"C:\Users\user\PycharmProjects\StockWise\models\NASDAQ-training set"
TEST_DIR = r"C:\Users\user\PycharmProjects\StockWise\models\NASDAQ-testing set"
FEATURE_COLS = ["Volume_Relative", "Volume_Delta", "Turnover", "Volume_Spike"]
REPORT_NAME = "model_performance_summary.csv"

# === INITIALIZE SESSION STATE FOR SLIDER RESET ===
if "reset_filters" not in st.session_state:
    st.session_state.reset_filters = False


# def settings_panel(ticker_list):
#     st.sidebar.title("üîß Settings")
#
#     symbol = st.sidebar.selectbox("üìå Select Stock Symbol", options=sorted(ticker_list))
#
#     date_option = st.sidebar.selectbox("üìÖ Data Range", [
#         "Today", "3 Days Ago", "7 Days Ago", "1 Month Ago", "1 Year Ago", "View All"
#     ])
#
#     run_button = st.sidebar.button("‚ñ∂Ô∏è Run Prediction")
#
#     # üìä Trade simulation parameters
#     with st.sidebar.container():
#         st.markdown("üß† Trade Simulation Settings")
#         take_profit = st.sidebar.slider("Take Profit (%)", 1, 20, value=7) / 100
#         stop_loss = st.sidebar.slider("Stop Loss (%)", 1, 20, value=3) / 100
#         max_hold = st.sidebar.slider("Max Hold Days", 5, 30, value=15)
#         min_conf = st.sidebar.slider("Minimum Confidence", 0.0, 1.0, value=0.5, step=0.05)
#
#     # üíæ Trade entry parameters
#     save_data = st.sidebar.checkbox("üíæ Save Trade to Google Sheet")
#     trade_entry = {}
#     if save_data:
#         st.sidebar.markdown("**Trade Entry**")
#         trade_entry["price"] = st.sidebar.number_input("Price", min_value=0.0)
#         trade_entry["date"] = st.sidebar.date_input("Date", value=datetime.today())
#         trade_entry["type"] = st.sidebar.selectbox("Buy / Sell", ["Buy", "Sell"])
#         trade_entry["state_tax"] = st.sidebar.number_input("State Tax", min_value=0.0)
#         trade_entry["commission"] = st.sidebar.number_input("Trading Commission", min_value=0.0)
#         trade_entry["notes"] = st.sidebar.text_input("Notes")
#
#     show_history = st.sidebar.checkbox("üìú Show Transaction History")
#
#     return {
#         "symbol": symbol,
#         "date_option": date_option,
#         "run_button": run_button,
#         "take_profit": take_profit,
#         "stop_loss": stop_loss,
#         "max_hold": max_hold,
#         "min_conf": min_conf,
#         "save_data": save_data,
#         "trade_entry": trade_entry,
#         "show_history": show_history,
#     }


def custom_shift_column(df, col, shift_n, debug=DEBUG_MODE):
    """
    üìö Shifts a column forward or backward with NaN padding.
    üì• Parameters:
    df: pd.DataFrame ‚Äî input DataFrame
    col: str ‚Äî column name to shift
    shift_n: int ‚Äî number of rows to shift (positive or negative)
    debug: bool ‚Äî enable debug logging
    üì§ Returns: pd.Series ‚Äî shifted column aligned with original index
    """

    df = df.reset_index(drop=True)
    values = df[col].values

    if debug:
        st.write(f"[DEBUG] function name: custom_shift_column")
        st.write(f"[DEBUG] Shifting column: {col}")
        st.write(f"[DEBUG] Original dtype: {df[col].dtype}")
        st.write(f"[DEBUG] Sample value before shift: {df[col].iloc[0]}")
        st.write(f"[DEBUG] Shift amount: {shift_n}")

    try:
        if shift_n > 0:
            shifted = np.concatenate([np.full(shift_n, np.nan), values[:-shift_n]])
        elif shift_n < 0:
            shifted = np.concatenate([values[-shift_n:], np.full(-shift_n, np.nan)])
        else:
            shifted = values.copy()
    except Exception as e:
        st.write(f"[ERROR] Custom shift failed on column {col}: {e}")
        raise

    return pd.Series(shifted, index=df.index)


def get_safe_window(df, center_idx, before=20, after=25):
    """
    üìö Returns a safe slice of rows around a given integer index,
    guaranteeing that df has integer-based indexing.
    üì• Parameters:
    df: pd.DataFrame ‚Äî input DataFrame
    center_idx: int ‚Äî center row index
    before: int ‚Äî rows before center
    after: int ‚Äî rows after center
    üì§ Returns: pd.DataFrame ‚Äî sliced window of rows
    """

    if not isinstance(center_idx, int):
        raise ValueError("center_idx must be an integer row position.")

    df = df.reset_index(drop=True)  # ‚õë ensures integer-based indexing
    start = max(0, center_idx - before)
    end = min(len(df), center_idx + after)
    return df.iloc[start:end].copy()


def get_future_price(df, col, idx, shift_n):
    """
    üìö Gets the future value of a column at a shifted index.
    üì• Parameters:
    df: pd.DataFrame ‚Äî input DataFrame
    col: str ‚Äî column to extract from
    idx: int ‚Äî current row index
    shift_n: int ‚Äî how far to look ahead or behind
    üì§ Returns: float or value ‚Äî future value at shifted index
    """

    shifted = custom_shift_column(df, col, shift_n, debug=DEBUG_MODE)
    return shifted.iloc[idx]


def safe_shift_diff(df, col, shift_n, debug=False):
    """
    Shift column safely and compute absolute difference, avoiding Timestamp arithmetic.
    Computes the absolute difference between a column and its shifted version.
    üì• Parameters:
    df: pd.DataFrame ‚Äî input DataFrame
    col: str ‚Äî column to compare
    shift_n: int ‚Äî shift amount
    debug: bool ‚Äî enable debug logging
    üì§ Returns: pd.Series ‚Äî absolute difference (or timedelta if datetime)
    """

    df_copy = df.copy().reset_index(drop=True)
    original = df_copy[col]

    if debug:
        st.write(f"[DEBUG] safe_shift_diff: col = {col}, shift_n = {shift_n}")
        st.write(f"[DEBUG] dtype of original: {original.dtype}")
        st.write(f"[DEBUG] sample: {original.iloc[0]}")

    try:
        if pd.api.types.is_datetime64_any_dtype(original):
            original_ns = original.view(np.int64)
            shifted_ns = custom_shift_column(df_copy, col, shift_n, debug=debug).view(np.int64)
            diff = np.abs(shifted_ns - original_ns)
            return pd.to_timedelta(diff)
        else:
            shifted = custom_shift_column(df_copy, col, shift_n, debug=debug)
            return (shifted - original).abs()
    except Exception as e:
        st.write(f"[ERROR in safe_shift_diff] {e}")
        return pd.Series([np.nan] * len(df_copy))


def get_slice_around(df, row_idx, before=20, after=25):
    """
    Safely return a slice of a DataFrame around a given row index.

    Args:
        df (pd.DataFrame): The full DataFrame (should be integer indexed).
        row_idx (int): Center row index.
        before (int): Number of rows to include before the index.
        after (int): Number of rows to include after the index.

    Returns:
        pd.DataFrame: Sliced window for visualization or analysis.
    """
    if not isinstance(row_idx, int):
        raise ValueError("row_idx must be an integer")

    start = max(0, row_idx - before)
    end = min(len(df), row_idx + after)
    return df.iloc[start:end].copy()


def run_backtest(stock_file, model_name, selected_time, debug=DEBUG_MODE):
    """
        üìà Run Backtest on a Selected Stock and Model
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    This function performs a forward-looking backtest using a trained model on a selected stock.
    It scans for the first BUY signal after the selected date, evaluates the model's prediction,
    calculates the future return, and displays the results in Streamlit.

    üîç What It Does:
    - Loads feature data for the selected stock
    - Loads the trained model
    - Scans forward from the selected date to find the first BUY signal
    - Calculates the entry price and future price (5-day lookahead)
    - Computes return and model confidence
    - Displays results and debug logs in Streamlit

    üì• Parameters:
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    stock_file : str
        Path to the feature-enriched stock data file (e.g., .parquet)
    model_name : str
        Name of the trained model to load (without .pkl extension)
    selected_time : str or datetime
        The user-selected date to start scanning from
    debug : bool
        If True, enables verbose debug output in Streamlit

    üì§ Returns:
    ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    None ‚Äî Outputs results directly to the Streamlit interface

    üìù Notes:
    - Uses a 5-day forward price shift to calculate return
    - Assumes model is trained on FEATURE_COLS
    - Can be extended to include fees, taxes, or stop-loss logic
    """
    try:
        # 1Ô∏è‚É£ Load and sanitize test data
        selected_time = pd.to_datetime(selected_time).date()
        if DEBUG_MODE:
            st.write(f"[DEBUG] Selected model: {model_name}")
            st.write(f"[DEBUG] Selected date: {selected_time}")

        test_df = load_features(stock_file)
        if debug:
            st.write(f"[DEBUG] Selected test stock file: {stock_file}")
            st.write(f"[DEBUG] Loaded test_df shape: {test_df.shape}")
            st.write(f"[DEBUG] test_df columns: {test_df.columns.tolist()}")

        test_df["Datetime"] = pd.to_datetime(test_df["Datetime"])
        test_df["DateOnly"] = test_df["Datetime"].dt.date
        test_df = test_df.reset_index(drop=True)  # üîê Ensure integer indexing
        if debug:
            st.write(f"[DEBUG] function name: run_backtest- A")
            st.write(f"[DEBUG] test_df = {test_df}")
        # 2Ô∏è‚É£ Locate the row for the selected date
        row_idx_list = test_df.index[test_df["DateOnly"] == selected_time].tolist()
        if debug:
            st.write(f"[DEBUG] function name: run_backtest- B")
            st.write(f"[DEBUG] row_idx_list = {row_idx_list}")
        if not row_idx_list:
            st.warning("‚ö†Ô∏è No data found for the selected date.")
            return
        row_idx = int(row_idx_list[0])
        if debug:
            st.write(f"[DEBUG] function name: run_backtest- C")
            st.write(f"[DEBUG] row_idx = {row_idx}")

        # 3Ô∏è‚É£ Prepare row for prediction
        # row = test_df.iloc[[row_idx]]
        # entry_idx = min(row_idx + 1, len(test_df) - 1)  # Move one row forward (or more if needed)
        # entry_row = test_df.iloc[[entry_idx]]
        # ts_entry = test_df["Datetime"].iloc[entry_idx]
        # row = entry_row
        # üß† Scan forward for first buy signal after selected date

        close_col = extract_price_column(test_df)
        if close_col is None or close_col not in test_df.columns:
            st.error(f"‚ùå Price column `{close_col}` not found. Aborting backtest.")
            return
        model_path = os.path.join(TRAIN_DIR, f"{model_name}.pkl")
        mdl = joblib.load(model_path)

        # 4Ô∏è‚É£ Scan forward for first BUY signal
        entry_idx = None
        for i in range(row_idx + 1, len(test_df)):
            row_candidate = test_df.iloc[[i]]
            pred = mdl.predict(row_candidate[FEATURE_COLS])[0]
            if pred == 1:
                entry_idx = i
                entry_row = row_candidate
                break

        # üö® Handle case: no signal found
        if entry_idx is None:
            st.warning("‚ö†Ô∏è No BUY signal detected after the selected date.")
            return

        # 5Ô∏è‚É£ Predict and evaluate
        ts_entry = test_df["Datetime"].iloc[entry_idx]
        entry_price = entry_row[close_col].values[0]
        future_series = custom_shift_column(test_df, close_col, shift_n=-5, debug=debug)
        future_price = future_series.iloc[entry_idx]
        pct_return = (future_price - entry_price) / entry_price * 100

        # üßæ Apply commission and state tax
        # net_profit = future_price - entry_price - settings["commission"] - state_tax
        # net_return = (net_profit / entry_price) * 100
        #
        # st.markdown(f"""
        # - **üìà Signal**: {'BUY' if pred == 1 else 'No Signal'}
        # - **Confidence**: `{prob:.2%}`
        # - **Entry Price**: `${entry_price:.2f}`
        # - **Future Price**: `${future_price:.2f}`
        # - **Gross Return**: `{pct_return:.2f}%`
        # - **Net Return (after fees)**: `{net_return:.2f}%`
        # - **Fees Paid**: `${commission:.2f} + ${state_tax:.2f}`
        # """)

        pred = mdl.predict(entry_row[FEATURE_COLS])[0]
        prob = mdl.predict_proba(entry_row[FEATURE_COLS])[0, 1]

        st.markdown(f"""
                - **üìà Signal**: {'BUY' if pred == 1 else 'No Signal'}  
                - **Confidence**: `{prob:.2%}`  
                - **Entry Price**: `${entry_price:.2f}`  
                - **Future Price**: `${future_price:.2f}`  
                - **Return**: `{pct_return:.2f}%`
                """)

        # row = entry_row
        # entry_price = entry_row[close_col].values[0]

        if debug:
            st.write(f"[DEBUG] function name: run_backtest- D")
            st.write(f"[DEBUG] row = {row}")
            st.write(f"[DEBUG] test_df")
            st.write(test_df)

        # close_col = extract_price_column(test_df)

        if debug:
            st.write(f"[DEBUG] function name: run_backtest- E")
            st.write(f"[DEBUG] row_idx = {close_col}")
        if close_col is None or close_col not in test_df.columns:
            st.error(f"‚ùå Price column `{close_col}` not found in test_df. Aborting backtest.")
            st.write("Available columns:", test_df.columns.tolist())
            return

        # entry_price = row[close_col].values[0]
        # entry_price = entry_row[close_col].values[0]
        if debug:
            st.write(f"[DEBUG] function name: run_backtest- 1")
            st.write(f"[DEBUG] row_idx = {row_idx}")
            st.write(f"[DEBUG] close_col = {close_col}")
            st.write(f"[DEBUG] Entry price type: {type(entry_price)}, value: {entry_price}")
            st.write(f"[DEBUG] test_df[close_col].dtype = {test_df[close_col].dtype}")
            st.write(f"[DEBUG] Future price shift source = {close_col}, shift_n = -5")

        # 6Ô∏è‚É£ Chart prep
        ts_target = test_df["Datetime"].iloc[min(entry_idx + 5, len(test_df) - 1)]
        candle_df = get_safe_window(test_df, entry_idx)
        vol_col = [col for col in candle_df.columns if "Volume_" in col][0]

        # # üîÑ Future price shift (safe index handling)
        # future_series = custom_shift_column(test_df, close_col, shift_n=-5, debug=DEBUG_MODE)
        # # future_price = future_series.iloc[row_idx]
        # future_price = future_series.iloc[entry_idx]
        # pct_return = (future_price - entry_price) / entry_price * 100
        #
        # # 4Ô∏è‚É£ Load model and make prediction
        # model_path = os.path.join(TRAIN_DIR, f"{model_name}.pkl")
        # mdl = joblib.load(model_path)
        # pred = mdl.predict(row[FEATURE_COLS])[0]
        # prob = mdl.predict_proba(row[FEATURE_COLS])[0, 1]
        #
        # # 5Ô∏è‚É£ Display result
        # st.markdown(f"""
        # - **üìà Signal**: {'BUY' if pred == 1 else 'No Signal'}
        # - **Confidence**: `{prob:.2%}`
        # - **Entry Price**: `${entry_price:.2f}`
        # - **Future Price**: `${future_price:.2f}`
        # - **Return**: `{pct_return:.2f}%`
        # """)

        # candle_df = get_safe_window(test_df, row_idx)

        if debug:
            st.write("[DEBUG] üîç Candle chart pre-check")
            st.write(f"[DEBUG] Expected close_col: {close_col}")
            st.write(f"[DEBUG] candle_df columns: {candle_df.columns.tolist()}")
            st.write(f"[DEBUG] test_df columns: {test_df.columns.tolist()}")

            if close_col not in candle_df.columns:
                st.warning(f"[DEBUG WARNING] Column `{close_col}` missing from candle_df!")
            if close_col not in test_df.columns:
                st.warning(f"[DEBUG WARNING] Column `{close_col}` missing from test_df!")

            st.write("[DEBUG] function name: run_backtest - 2")
            st.write(f"üîç DEBUG: Evaluating error on col {close_col}")
            st.write(f"Type: {test_df[close_col].dtype}, sample: {test_df[close_col].iloc[0]}")
            st.write(f"Index type: {type(test_df.index)}")

        if close_col not in candle_df.columns:
            st.warning(f"‚ö†Ô∏è Column `{close_col}` not found in candlestick DataFrame.")
            st.write("üîç Available columns:", candle_df.columns.tolist())
            return

        # ts_val = test_df["Datetime"].iloc[row_idx]
        # unix_ts = int(ts_val.timestamp())
        # timestamp_in_ms = 1711929600000
        # selected_time = timestamp_in_ms + unix_ts

        # ts_val = test_df["Datetime"].iloc[row_idx]  # Selected timestamp
        ts_val = ts_entry
        future_idx = min(row_idx + 5, len(test_df) - 1)  # Safe bound
        ts_target = test_df["Datetime"].iloc[future_idx]
        # ts_target = ts_val + pd.Timedelta(days=5)  # Prediction horizon
        unix_ts = ts_val.timestamp()  # üî• Proper numeric timestamp for add_vline

        if debug:
            st.write(f"[DEBUG] ts_val type: {type(ts_val)}, value: {ts_val}")
            st.write(f"[DEBUG] timestamp value: {unix_ts}, local_time: {ts_target}")
            st.write(f"[DEBUG] candle_df index type: {candle_df["Datetime"]}")

        fig = make_subplots(
            rows=2, cols=1,
            shared_xaxes=True,
            row_heights=[0.7, 0.3],
            vertical_spacing=0.05,
            specs=[[{"type": "candlestick"}], [{"type": "bar"}]]
        )

        # üìà Candlestick
        fig.add_trace(go.Candlestick(
            x=candle_df["Datetime"],
            open=candle_df[[col for col in candle_df.columns if "Open_" in col][0]],
            high=candle_df[[col for col in candle_df.columns if "High_" in col][0]],
            low=candle_df[[col for col in candle_df.columns if "Low_" in col][0]],
            close=candle_df[close_col],
            name="Price",
        ), row=1, col=1)

        # üìä Volume bars
        vol_col = [col for col in candle_df.columns if "Volume_" in col][0]
        fig.add_trace(go.Bar(
            x=candle_df["Datetime"],
            y=candle_df[vol_col],
            name="Volume",
            marker=dict(color="rgba(0,0,255,0.3)")
        ), row=2, col=1)

        # üìç Buy marker
        fig.add_trace(go.Scatter(
            x=[ts_val],
            y=[entry_price],
            mode="markers",
            marker=dict(symbol="arrow-bar-down", color="yellow", size=10),
            name="Entry Price"
        ), row=1, col=1)

        # üéØ Target marker
        fig.add_trace(go.Scatter(
            x=[ts_target],
            y=[future_price],
            mode="markers",
            marker=dict(symbol="arrow-bar-up", color="blue", size=10),
            name="5-Day Target"
        ), row=1, col=1)

        # üéØ Selected date marker
        fig.add_trace(go.Scatter(
            x=[selected_time],
            y=[test_df[close_col].iloc[row_idx]],
            mode="markers",
            marker=dict(symbol="circle", color="white", size=10),
            name="5-Day Target"
        ), row=1, col=1)

        # # üü® Vline using timestamp
        # fig.add_vline(
        #     x=ts_entry,
        #     line=dict(color="orange", width=2, dash="dot"),
        #     annotation_text="Selected Day",
        #     annotation_position="top left"
        # )

        # üé® Layout settings
        fig.update_layout(
            title="üìâ Price Action & Volume with Signal Markers",
            xaxis_title="Date",
            yaxis_title="Price ($)",
            height=650,
            margin=dict(l=10, r=10, t=40, b=10),
            showlegend=True,
            xaxis_rangeslider_visible=False
        )

        st.plotly_chart(fig, use_container_width=True)

    except Exception as e:
        st.error(f"Something went wrong: {e}")


# === HELPER FUNCTIONS ===

def load_features(file_path):
    """
    üìö Loads a feature dataset from a .parquet file and ensures a Datetime column exists.
    üì• Parameters:
    file_path: str ‚Äî path to the .parquet file
    üì§ Returns: pd.DataFrame ‚Äî cleaned feature dataset
    """

    try:
        df = pd.read_parquet(file_path)
        df = df.dropna()

        if "Datetime" not in df.columns:
            # ‚è± Create dummy datetime index
            df = df.reset_index(drop=True)
            df["Datetime"] = pd.date_range(
                start="2023-01-01", periods=len(df), freq="1D"  # Change "1D" to "5min" or "1h" if intraday
            )

        return df
    except Exception as e:
        st.write(f"Failed to load {file_path}: {e}")
        return None


def extract_price_column(df, debug=DEBUG_MODE):
    """
    üìö Extracts the first column that starts with "Close_".
    üì• Parameters:
    df: pd.DataFrame ‚Äî input DataFrame
    debug: bool ‚Äî enable debug logging
    üì§ Returns: str ‚Äî name of the close price column
    """
    try:
        close_cols = [col for col in df.columns if col.startswith("Close_")]
        if debug:
            st.write(f"[DEBUG] Extracted price column: {close_cols}")

        if not close_cols:
            raise ValueError("No column found starting with 'Close_'.")
        return close_cols[0]
    except Exception as e:
        st.warning(f"Failed to extract price column: {e}")
        return None


def evaluate_model_on_df(model, df, close_col):
    """
    üìö Evaluates a model on a given DataFrame and returns performance metrics.
    üì• Parameters:
    model: sklearn-compatible model
    df: pd.DataFrame ‚Äî feature dataset
    close_col: str ‚Äî name of the close price column
    üì§ Returns: [f1, precision, recall, hit_rate, avg_abs_err, avg_prob]
    """

    X = df[FEATURE_COLS]
    y_true = df["Target"]

    try:
        y_pred = model.predict(X)
        y_prob = model.predict_proba(X)[:, 1]
    except Exception as e:
        st.write("Prediction error:", e)
        return [None] * 6

    f1 = f1_score(y_true, y_pred, zero_division=0)
    precision = precision_score(y_true, y_pred, zero_division=0)
    recall = recall_score(y_true, y_pred, zero_division=0)
    hit_rate = np.sum((y_pred == 1) & (y_true == 1)) / max(1, np.sum(y_true == 1))
    shifted_col = custom_shift_column(df, close_col, shift_n=-5, debug=DEBUG_MODE)
    if DEBUG_MODE:
        st.write("[DEBUG] function name: evaluate_model_on_df")
        st.write(f"üîç DEBUG: Evaluating error on col {close_col}")
        st.write(f"Type: {df[close_col].dtype}, sample: {df[close_col].iloc[0]}")
        st.write(f"Index type: {type(df.index)}")

    price_diff = np.abs(shifted_col - df[close_col])
    avg_abs_err = price_diff[y_pred == 1].mean()
    avg_prob = y_prob[y_pred == 1].mean() if np.sum(y_pred == 1) > 0 else 0

    return [f1, precision, recall, hit_rate, avg_abs_err, avg_prob]


def stock_list():
    """
    üìö Scrapes a list of NASDAQ stocks from StockAnalysis.com..
    üì• Parameters: None
    üì§ Returns: List[str] ‚Äî formatted as "Company Name - SYMBOL"
    """

    url = "https://stockanalysis.com/list/nasdaq-stocks/"
    tables = pd.read_html(url)
    df = tables[0]  # First table contains the stock list

    # Extract and format
    stock_pairs = [f"{row['Company Name']} - {row['Symbol']}" for _, row in df.iterrows()]
    return stock_pairs.sort()


# === EVALUATE ALL MODELS AND GENERATE CSV ===
def main():
    """
    üìö Evaluates all models and generates a performance summary CSV.
    üì• Parameters: None
    üì§ Returns: None (outputs to Streamlit and saves CSV)

    What it does:
    Loads all models and test datasets
    Evaluates each model on its training data
    Tests each model on 10 random test stocks
    Computes average metrics across test runs
    Saves results to model_performance_summary.csv
    Displays progress bar and status updates
    """

    # settings = settings_panel(stock_list())
    # if DEBUG_MODE:
    #     st.write(f"[DEBUG] settings: {settings}")
    # selected_symbol = settings["symbol"]
    # stop_loss = settings["stop_loss"]
    model_files = sorted(glob.glob(os.path.join(TRAIN_DIR, "*_model_*.pkl")))
    test_feature_files = sorted(glob.glob(os.path.join(TEST_DIR, "*_features_*.parquet")))
    all_rows = []


    progress_bar = st.progress(0)
    status_text = st.empty()
    total_models = len(model_files)

    for i, model_path in enumerate(model_files):
        model_name = os.path.basename(model_path).replace(".pkl", "")
        stock_symbol = model_name.split("_")[0]

        progress = int((i + 1) / total_models * 100)
        progress_bar.progress(progress)
        status_text.text(f"üîÑ Evaluating model {i+1}/{total_models}: `{model_name}`")

        match = glob.glob(os.path.join(TRAIN_DIR, f"{stock_symbol}_features_*.parquet"))
        if not match:
            continue

        train_df = load_features(match[0])
        if train_df is None or train_df.empty:
            continue

        close_col = extract_price_column(train_df)
        model = joblib.load(model_path)
        in_f1, in_prec, in_rec, in_hit, in_err, in_prob = evaluate_model_on_df(model, train_df, close_col)

        test_f1s, test_prec, test_rec, test_hit, test_errs, test_probs = [], [], [], [], [], []
        for test_file in np.random.choice(test_feature_files, size=10, replace=False):
            test_df = load_features(test_file)
            if test_df is None or test_df.empty:
                continue
            close_col = extract_price_column(test_df)
            if close_col is None or close_col not in test_df.columns:
                if DEBUG_MODE:
                    st.write(f"[DEBUG WARNING] Column `{close_col}` missing from {os.path.basename(test_file)}")
                    st.write(f"Available columns: {test_df.columns.tolist()}")
                continue

            f1, p, r, h, e, prob = evaluate_model_on_df(model, test_df, close_col)
            if f1 is not None:
                test_f1s.append(f1)
                test_prec.append(p)
                test_rec.append(r)
                test_hit.append(h)
                test_errs.append(e)
                test_probs.append(prob)

        row = {
            "Model": model_name,
            "Train_F1": in_f1,
            "Train_Precision": in_prec,
            "Train_Recall": in_rec,
            "Train_HitRate": in_hit,
            "Train_ProbAvg": in_prob,
            "Train_AvgError": in_err,
            "Test_F1_avg": np.mean(test_f1s),
            "Test_Precision_avg": np.mean(test_prec),
            "Test_Recall_avg": np.mean(test_rec),
            "Test_HitRate_avg": np.mean(test_hit),
            "Test_ProbAvg": np.mean(test_probs),
            "Test_AvgError": np.mean(test_errs),
        }
        all_rows.append(row)

    progress_bar.empty()
    status_text.success("‚úÖ Model evaluation complete!")

    df_summary = pd.DataFrame(all_rows)
    df_summary = df_summary.sort_values("Test_F1_avg", ascending=False)
    df_summary.to_csv(REPORT_NAME, index=False)
    st.success(f"üìÅ Report saved: `{REPORT_NAME}`")


if __name__ == "__main__":
    """
    This section defines the interactive user interface and behavior of the Streamlit app. 
    It controls how users interact with the model evaluation system and backtesting engine
    
    üìå st.set_page_config(...) Sets the layout and title of the app
    üöÄ st.button("Run Evaluation and Generate Report") Triggers the main() function to evaluate all models
    
    What It Does:
    Sets up the app layout and title
    Provides a button to trigger model evaluation across all saved models
    Loads and displays the leaderboard from the generated CSV report
    
    
    Offers sidebar filters for:
    Loads the CSV report
    Minimum F1 score
    Maximum average error
    Minimum hit rate
    Displays a sorted table of top-performing models
    
    Displays interactive charts:
    F1 vs. Error (bubble chart)
    Hit Rate vs. Precision
    Error Standard Deviation vs. F1
    
    üéõÔ∏è Sidebar Filters:
    Interactive sliders for F1, error, and hit rate
    Reset button to restore default filter values
    
    Allows users to:
    Select a specific stock file
    Choose a trained model
    Pick a date
    Run a manual backtest using the selected configuration
    
    üì§ Outputs:
    Dynamic tables, charts, and backtest results rendered in the Streamlit interface
    
    """

    # === DASHBOARD ===
    st.set_page_config(layout="wide")
    st.title("üèÜ NASDAQ Model Performance Evaluation")

    # Run evaluation
    if st.button("üöÄ Run Evaluation and Generate Report"):
        with st.spinner("Crunching models..."):
            main()
        # st.experimental_rerun()

    # Leaderboard dashboard
    if os.path.exists(REPORT_NAME):

        df = pd.read_csv(REPORT_NAME)
        df = df.dropna(subset=["Test_F1_avg"])
        df = df.sort_values("Test_F1_avg", ascending=False)

        # üî¢ Rank models by performance (Test_F1_avg desc)
        df_ranked = df.dropna(subset=["Test_F1_avg"]).copy()
        df_ranked = df_ranked.sort_values("Test_F1_avg", ascending=False)
        ranked_model_names = df_ranked["Model"].tolist()

        # === SIDEBAR FILTERS ===
        with st.sidebar:
            with st.expander("üìå What do these filters do?"):
                st.markdown("""
                Filters:
                - **F1 Score** ‚Üí higher is better  
                - **Avg Error ($)** ‚Üí lower is better  
                - **Hit Rate** ‚Üí higher is better  
                """)

            # Sliders using session state values
            st.session_state.min_f1 = st.slider("üîç Min Test F1", 0.0, 1.0, st.session_state.min_f1, 0.05, key="f1")
            st.session_state.max_err = st.slider("üßØ Max Avg Error", 0.0, 25.0, st.session_state.max_err, 0.5, key="err")
            st.session_state.min_hit = st.slider("üéØ Min Hit Rate", 0.0, 1.0, st.session_state.min_hit, 0.05, key="hit")

            # Reset button to restore all
            if st.button("üîÑ Restore Defaults"):
                st.session_state.min_f1 = 0.2
                st.session_state.max_err = 10.0
                st.session_state.min_hit = 0.3
                st.experimental_rerun() if hasattr(st, "experimental_rerun") else st.stop()

        # Apply filters
        filtered = df[
            (df["Test_F1_avg"] >= st.session_state.min_f1) &
            (df["Test_AvgError"] <= st.session_state.max_err) &
            (df["Test_HitRate_avg"] >= st.session_state.min_hit)
            ]

        # Format + display table
        with st.expander("üìä Model Performance Leaderboard ‚Äî What does this show?"):
            st.markdown("""
            Each row is a model:
            - **F1, Hit Rate, Prob Avg** ‚Üí _Higher is better_
            - **Avg Error** ‚Üí _Lower is better_
            Use filters to zero in on generalizable, accurate models.
            """)

        numeric_cols = [
            "Train_F1", "Train_Precision", "Train_Recall", "Train_HitRate",
            "Train_ProbAvg", "Train_AvgError", "Test_F1_avg", "Test_Precision_avg",
            "Test_Recall_avg", "Test_HitRate_avg", "Test_ProbAvg", "Test_AvgError"
        ]
        for col in numeric_cols:
            if col in filtered.columns:
                filtered[col] = pd.to_numeric(filtered[col], errors="coerce")

        format_dict = {col: "{:.2f}" for col in numeric_cols if col in filtered.columns}
        try:
            st.dataframe(filtered.style.format(format_dict), use_container_width=True)
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Table display failed: {e}")
            st.dataframe(filtered, use_container_width=True)

            # === üìà F1 vs Error Chart ===
        with st.expander("üìà F1 vs Error ‚Äî How to read this chart"):
            st.markdown("""
                    Each dot = a model  
                    - **Higher = better F1 score**  
                    - **Left = lower error** (good!)  
                    - **Bubble size = Hit Rate**, **Color = Confidence**  
                    Goal: Top-left zone ‚úÖ
                    """)
        fig1 = px.scatter(
            filtered,
            x="Test_AvgError",
            y="Test_F1_avg",
            hover_name="Model",
            color="Test_ProbAvg",
            size="Test_HitRate_avg",
            color_continuous_scale="Viridis"
        )
        st.plotly_chart(fig1, use_container_width=True)

        # === üéØ Hit Rate vs Precision Chart ===
        with st.expander("üéØ Hit Rate vs Precision ‚Äî What's good here?"):
            st.markdown("""
                    Top-right is ideal üíØ  
                    - **Hit Rate**: % of correct spike predictions  
                    - **Precision**: % of predicted spikes that were real  
                    - Color = Avg Error ($) ‚Üí Lighter is better
                    """)
        fig2 = px.scatter(
            filtered,
            x="Test_HitRate_avg",
            y="Test_Precision_avg",
            hover_name="Model",
            color="Test_AvgError",
            color_continuous_scale="Plasma"
        )
        st.plotly_chart(fig2, use_container_width=True)

        # === üìâ Optional: STD of Prediction Error ===
        with st.expander("üìâ Std. Dev. of Error ‚Äî Why it matters"):
            st.markdown("""
                    Shows volatility of a model's predictions:  
                    - **Lower STD** = More consistent accuracy ‚úÖ  
                    - **High STD** = Erratic predictions ‚ö†Ô∏è
                    """)

        if "Error_STD" not in filtered.columns:
            filtered["Error_STD"] = np.nan
            for idx, row in filtered.iterrows():
                model_name = row["Model"]
                stock_symbol = model_name.split("_")[0]
                test_files = glob.glob(os.path.join(TEST_DIR, f"{stock_symbol}_features_*.parquet"))
                if not test_files:
                    continue
                test_df = load_features(test_files[0])
                if test_df is None or test_df.empty:
                    continue
                try:
                    model_path = os.path.join(TRAIN_DIR, f"{model_name}.pkl")
                    model = joblib.load(model_path)
                    X = test_df[FEATURE_COLS]
                    preds = model.predict(X)
                    close_col = extract_price_column(test_df)
                    err_series = safe_shift_diff(test_df, close_col, shift_n=5,debug=DEBUG_MODE)[preds == 1]
                    filtered.at[idx, "Error_STD"] = err_series.std()
                except Exception:
                    continue

        fig3 = px.scatter(
            filtered.dropna(subset=["Error_STD"]),
            x="Error_STD",
            y="Test_F1_avg",
            hover_name="Model",
            color="Test_ProbAvg",
            size="Test_HitRate_avg",
            labels={"Error_STD": "Error STD ($)", "Test_F1_avg": "F1 Score"},
            color_continuous_scale="Inferno"
        )
        st.plotly_chart(fig3, use_container_width=True)
    st.markdown("## üîÅ Backtest a Specific Scenario")

    with st.expander("üîç How it works"):
        st.markdown("""
        Use this tool to test a specific model on new data from a stock and date it wasn't trained on.  
        It will simulate whether the model would have issued a 'buy signal', and how far the stock actually moved.  
        """)

    # Input widgets
    stock_file = st.selectbox("üìÑ Choose a test stock file", sorted(glob.glob(os.path.join(TEST_DIR, "*_features_*.parquet"))))
    model_name = st.selectbox("ü§ñ Choose a trained model", ranked_model_names)
    # selected_index = st.number_input("üìç Row index to simulate (e.g. 100)", min_value=0, step=1)
    test_df = load_features(stock_file).reset_index(drop=True)
    time_col = test_df.index if isinstance(test_df.index, pd.DatetimeIndex) else test_df["Datetime"]  # adjust if needed
    # selected_time = st.selectbox("üïí Choose date/time", time_col.astype(str))
    selected_time = st.date_input("üïí Choose time", value="today")# test_df["Datetime"].astype(str))
    selected_time = pd.to_datetime(selected_time).date()  # ensure it's a date object

    # Create a 'date only' column from your Datetime column
    test_df["DateOnly"] = pd.to_datetime(test_df["Datetime"]).dt.date

    # Find the first row where the date matches
    match_indices = test_df.index[test_df["DateOnly"] == selected_time].tolist()

    if match_indices:
        row_idx = match_indices[0]
        row = test_df.iloc[[row_idx]]
        # (continue as before...)
    else:
        st.warning("No data found for that date ‚Äî try a different day.")

    # Button to run the test
    if st.button("‚ñ∂Ô∏è Run Backtest"):
        run_backtest(stock_file, model_name, selected_time, debug=DEBUG_MODE)


