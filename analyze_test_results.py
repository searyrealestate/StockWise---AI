"""
ðŸ“Š Analyze Test Results for StockWise Model
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

This script loads the evaluation summary CSV generated by `model_evaluator.py`
and provides a detailed analysis of your model's performance across all test stocks.

It computes:
- Average accuracy, F1 score, recall, and precision
- Top 5 and bottom 5 performing stocks (by F1 score)
- A cleaned summary CSV with key metrics only


Usage:
â”€â”€â”€â”€â”€â”€â”€
Run this script after evaluating your model:
$ python analyze_test_results.py

Make sure the file 'summary_lgbm_tech-dynamic-days-window.csv' exists in the project root.
"""

import pandas as pd
import matplotlib.pyplot as plt
import os
import time
import matplotlib.dates as mdates
import numpy as np
from tqdm import tqdm

def config():
    SUMMARY_FILE = "summary_lgbm_tech-dynamic-days-window-400stocks.csv"
    FEATURE_DIR = "models/NASDAQ-testing set"
    PLOT_DIR = "fft_plots"

    return SUMMARY_FILE, FEATURE_DIR, PLOT_DIR


def compute_fft_features(returns, window=64):
    returns = returns.dropna()
    returns = returns - returns.mean()  # Remove DC component

    if len(returns) < window:
        return None, None, None, None, None

    fft_vals = np.fft.fft(returns[-window:])
    fft_power = np.abs(fft_vals)**2
    fft_freqs = np.fft.fftfreq(len(fft_power))
    n = len(fft_power)

    # Positive frequencies only
    positive_freqs = fft_freqs[:n // 2]
    fft_power_db = 10 * np.log10(fft_power[:n // 2] + 1e-10)

    # Summary stats
    high_freq_energy = fft_power[n//4:].sum()
    low_freq_energy = fft_power[:n//4].sum()
    noise_ratio = high_freq_energy / (low_freq_energy + 1e-6)

    return positive_freqs, fft_power_db, high_freq_energy, low_freq_energy, noise_ratio


from joblib import Parallel, delayed


def analyze_single_stock(file, feature_dir, output_dir):
    symbol = file.split("_")[0]
    path = os.path.join(feature_dir, file)

    try:
        df = pd.read_parquet(path)

        if "Close" not in df.columns or "Volume" not in df.columns:
            return None

        df["returns"] = df["Close"].pct_change()
        df["returns_ma"] = df["returns"].rolling(window=10).mean()
        df["returns_std"] = df["returns"].rolling(window=10).std()
        df["vol_upper"] = df["returns_ma"] + 2 * df["returns_std"]
        df["vol_lower"] = df["returns_ma"] - 2 * df["returns_std"]

        freqs, power_db, hf, lf, ratio = compute_fft_features(df["returns"])
        if freqs is None:
            return None

        # Plot
        fig, axs = plt.subplots(4, 1, figsize=(12, 8), sharex=False)
        fig.suptitle(f"{symbol} â€” Price, Volume, Returns, FFT", fontsize=14)

        axs[0].plot(df["Close"], color="blue")
        axs[0].set_ylabel("Price")
        axs[0].grid(True)

        axs[1].plot(df["Volume"], color="orange")
        axs[1].set_ylabel("Volume")
        axs[1].grid(True)

        axs[2].plot(df["returns"], color="green", alpha=0.4)
        axs[2].plot(df["returns_ma"], color="black", linewidth=1.5)
        axs[2].fill_between(df.index, df["vol_lower"], df["vol_upper"], color="gray", alpha=0.2)
        axs[2].set_ylabel("Returns")
        axs[2].grid(True)

        axs[3].bar(freqs, power_db, color="purple", alpha=0.7)
        axs[3].set_ylabel("FFT Power (dB)")
        axs[3].set_xlabel("Frequency")
        axs[3].grid(True)

        axs[2].xaxis.set_major_locator(mdates.AutoDateLocator())
        axs[2].xaxis.set_major_formatter(mdates.ConciseDateFormatter(axs[2].xaxis.get_major_locator()))

        plt.tight_layout(rect=[0, 0, 1, 0.95])
        plt.savefig(os.path.join(output_dir, f"{symbol}_fft.png"))
        plt.close()

        return {
            "symbol": symbol,
            "volatility": df["returns"].std(),
            "fft_high_freq_energy": hf,
            "fft_low_freq_energy": lf,
            "fft_noise_ratio": ratio
        }

    except Exception as e:
        print(f"âŒ Error processing {symbol}: {e}")
        return None


def analyze_all_stocks_parallel(feature_dir="models/NASDAQ-testing set", output_dir="fft_plots", n_jobs=4):
    os.makedirs(output_dir, exist_ok=True)
    files = [f for f in os.listdir(feature_dir) if f.endswith(".parquet")]

    results = Parallel(n_jobs=n_jobs)(
        delayed(analyze_single_stock)(file, feature_dir, output_dir) for file in tqdm(files)
    )

    results = [r for r in results if r is not None]
    summary_df = pd.DataFrame(results)
    summary_df.to_csv("fft_analysis_summary.csv", index=False)
    print("âœ… All plots saved to:", output_dir)
    print("ðŸ“„ Summary saved to: fft_analysis_summary.csv")


def inspect_stock(symbol, feature_dir="models/NASDAQ-testing set"):
    matches = [f for f in os.listdir(feature_dir) if f.startswith(f"{symbol}_features") and f.endswith(".parquet")]
    if not matches:
        print(f"âŒ File not found for {symbol}")
        return

    path = os.path.join(feature_dir, matches[0])
    df = pd.read_parquet(path)
    print(f"\nðŸ“ˆ {symbol} â€” {len(df)} rows")
    print("Columns:", df.columns.tolist())

    # Calculate returns and volatility
    if "Close" in df.columns:
        df["returns"] = df["Close"].pct_change()
        volatility = df["returns"].std()
        print(f"ðŸ“‰ Volatility (std of returns): {volatility:.4f}")
        if volatility < 0.01:
            print("âš ï¸ Low volatility â€” likely a sideways or illiquid stock")

    # Check for flat or missing features
    flat_cols = [col for col in df.columns if df[col].nunique() <= 1]
    print("âš ï¸ Flat or constant columns:", flat_cols)

    missing_cols = df.columns[df.isnull().any()].tolist()
    if missing_cols:
        print("ðŸš« Columns with missing values:", missing_cols)

    # Compute moving average and volatility band
    if "returns" in df.columns:
        df["returns_ma"] = df["returns"].rolling(window=10).mean()
        df["returns_std"] = df["returns"].rolling(window=10).std()
        df["vol_upper"] = df["returns_ma"] + 2 * df["returns_std"]
        df["vol_lower"] = df["returns_ma"] - 2 * df["returns_std"]

    # ðŸ“Š Create subplots
    fig, axs = plt.subplots(4, 1, figsize=(12, 8), sharex=False)
    fig.suptitle(f"{symbol} â€” Price, Volume, Returns, and FFT", fontsize=14)

    axs[0].plot(df["Close"], label="Close", color="blue")
    axs[0].set_ylabel("Price")
    axs[0].grid(True)

    axs[1].plot(df["Volume"], label="Volume", color="orange")
    axs[1].set_ylabel("Volume")
    axs[1].grid(True)

    if "returns" in df.columns:
        axs[2].plot(df["returns"], label="Returns", color="green", alpha=0.4)
        axs[2].plot(df["returns_ma"], label="MA(10)", color="black", linewidth=1.5)
        axs[2].fill_between(df.index, df["vol_lower"], df["vol_upper"], color="gray", alpha=0.2, label="Â±2Ïƒ Band")
        axs[2].set_ylabel("Returns")
        axs[2].legend()
        axs[2].grid(True)

        # FFT plot
        returns_fft = df["returns"].dropna().values[-64:]
        if len(returns_fft) >= 64:
            # Compute FFT and power spectrum
            fft_vals = np.fft.fft(returns_fft)
            fft_power = np.abs(fft_vals) ** 2
            fft_freqs = np.fft.fftfreq(len(fft_power))

            # Focus on positive frequencies only
            n = len(fft_power)
            positive_freqs = fft_freqs[:n // 2]
            fft_power_db = 10 * np.log10(fft_power[:n // 2] + 1e-10)  # Avoid log(0)

            # Plot FFT in dB
            colors = ["green" if f < 0.1 else "orange" if f < 0.25 else "red" for f in positive_freqs]
            axs[3].bar(positive_freqs, fft_power_db, color=colors, alpha=0.8)
            axs[3].set_ylabel("FFT Power (dB)")
            axs[3].set_xlabel("Frequency")
            axs[3].set_title("FFT of Returns (Last 64 Days)")
            axs[3].grid(True)

    axs[2].xaxis.set_major_locator(mdates.AutoDateLocator())
    axs[2].xaxis.set_major_formatter(mdates.ConciseDateFormatter(axs[2].xaxis.get_major_locator()))

    plt.tight_layout(rect=[0, 0, 1, 0.95])
    plt.show()


print("\nðŸ“Š Analyzing Bottom 10 Stocks for Volume, Volatility, and Feature Quality")

summary_file, FEATURE_DIR, PLOT_DIR = config()

# ðŸ”„ Run FFT analysis in parallel
analyze_all_stocks_parallel(FEATURE_DIR, PLOT_DIR)

# ðŸ“‚ Load the evaluation summary
df = pd.read_csv(summary_file)



# ðŸ‘€ Preview the first few rows
print("ðŸ” First few rows of the test summary:")
print(df.head())

# ðŸ“Š Compute overall performance metrics
print("\nðŸ“Š Model Performance on Test Set")
print("Average Accuracy :", df["accuracy"].mean())
print("Average F1 Score :", df["f1"].mean())
print("Average Recall   :", df["recall"].mean())
print("Average Precision:", df["precision"].mean())

# ðŸ“ˆ Top 5 performing stocks
print("\nðŸ“ˆ Top 5 Performing Stocks (by F1 Score)")
print(df.sort_values("f1", ascending=False).head(5))

# ðŸ“‰ Bottom 5 performing stocks
print("\nðŸ“‰ Bottom 5 Performing Stocks (by F1 Score)")
bottom_stocks = df.sort_values("f1", ascending=True).head(10)["symbol"].tolist()
print("\nðŸ”» Bottom 10 Stocks:", bottom_stocks)

top_stocks = df.sort_values("f1", ascending=False).head(5)["symbol"].tolist()
print("\nðŸ”º Top 5 Stocks:", top_stocks)

for symbol in top_stocks:
    inspect_stock(symbol, FEATURE_DIR)

fft_df = pd.read_csv("fft_analysis_summary.csv")
merged = df.merge(fft_df, on="symbol")
print("\nðŸ“‰ Correlation between noise ratio and F1 score:")
print(merged[["f1", "fft_noise_ratio"]].corr())

# ðŸ’¾ Optional: Save a clean summary
df[["symbol", "accuracy", "f1", "recall", "precision"]].to_csv("summary_clean.csv", index=False)
print("\nâœ… Saved cleaned summary to summary_clean.csv")
